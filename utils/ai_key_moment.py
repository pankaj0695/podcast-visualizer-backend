import os
import json
import re
from gtts import gTTS
from PIL import Image, ImageDraw, ImageFont
from moviepy import (
    VideoFileClip,
    ImageClip,
    AudioFileClip,
    CompositeVideoClip,
    concatenate_videoclips
)
from utils.vertex_ai_helper import generate_content_with_vertex_ai, generate_images_with_vertex_ai

WIDTH, HEIGHT = 432, 768
FONT_PATH = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
FONT_SIZE = 28

AI_PROMPT = '''You are a helpful assistant. Analyze the following podcast transcript and extract the top 3 most important key moments.

For each key moment, return:
- `image_prompts`: An array of 5-6 detailed, descriptive image prompts that visually represent the concepts discussed in this moment. Each prompt should be specific and vivid, suitable for AI image generation (e.g., "A futuristic laboratory with holographic displays showing DNA sequences and robotic arms conducting experiments", "A diverse group of scientists collaborating around a glowing AI interface in a modern research facility").
- `script`: A **first-person summary** of the moment written in a natural, conversational tone (e.g., "I realized...", "We discussed..."). The script should be approximately **60-75 words**, or **25-30 seconds** when read aloud.

Make the summaries insightful and engaging. Use **ONLY JSON format** in your response ‚Äî do NOT include timestamps, speaker names, or bullet points.

Example output:
[
  {
    "image_prompts": [
      "A futuristic cityscape with AI-powered robots helping humans in daily tasks",
      "A medical laboratory where AI algorithms analyze patient data on holographic screens",
      "A classroom where students interact with AI tutors through immersive virtual reality",
      "A research facility with scientists collaborating with AI to discover new medicines",
      "A smart home environment where AI assistants seamlessly integrate with family life",
      "A diverse team of ethicists and technologists discussing AI governance around a modern conference table"
    ],
    "script": "I talked about how artificial intelligence is completely transforming fields like healthcare and education. We explored how AI-driven tools are becoming more accessible and discussed the importance of responsible innovation. I realized the future isn't just about technology‚Äîit's also about how humans use it thoughtfully and ethically."
  },
  ...
]

Transcript:
'''

def extract_ai_key_moments(transcript_segments):
    """Extract key moments with AI image prompts instead of keywords"""
    transcript_text = "\n".join([t["text"] for t in transcript_segments])
    prompt = AI_PROMPT + transcript_text
    result = generate_content_with_vertex_ai(prompt)
    json_match = re.search(r"\[\s*{.*?}\s*\]", result, re.DOTALL)
    if json_match:
        return json.loads(json_match.group(0))
    raise ValueError("No valid JSON array found in the response.")

def generate_caption_clips(script, idx, total_dur):
    """Generate caption clips for the video"""
    words = script.split()
    chunks = [' '.join(words[i:i+4]) for i in range(0, len(words), 4)]  # 4-word chunks
    dur = total_dur / len(chunks)
    font = ImageFont.truetype(FONT_PATH, FONT_SIZE)
    clips = []
    img_files = []
    
    for j, chunk in enumerate(chunks):
        img = Image.new("RGBA", (WIDTH, HEIGHT), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        bbox = draw.textbbox((0,0), chunk, font=font)
        x = (WIDTH - (bbox[2]-bbox[0]))//2
        y = HEIGHT - (bbox[3]-bbox[1]) - 60  # Position at bottom with margin
        # Add dark background rectangle
        draw.rectangle([(x-10, y-10), (x+bbox[2]-bbox[0]+10, y+bbox[3]-bbox[1]+10)], fill=(0,0,0,180))
        draw.text((x,y), chunk, font=font, fill="white")
        fname = f"ai_caption_{idx}_{j}.png"
        img.save(fname)
        img_files.append(fname)
        clips.append(
            ImageClip(fname, transparent=True)
                .with_start(j*dur)
                .with_duration(dur)
                .with_position(("center", "bottom"))
        )
    return clips, img_files

def create_ai_key_moment_clip(moment, idx):
    """Create a video clip using AI-generated images instead of stock footage"""
    outdir = "ai_key_moments"
    os.makedirs(outdir, exist_ok=True)
    
    # Generate speech audio
    audio_file = f"ai_speech_{idx}.mp3"
    tts = gTTS(text=moment['script'], lang='en')
    tts.save(audio_file)
    audio = AudioFileClip(audio_file)
    total_dur = audio.duration
    
    # Generate AI images
    print(f"üé® Generating {len(moment['image_prompts'])} AI images for moment {idx+1}...")
    image_paths = generate_images_with_vertex_ai(moment['image_prompts'])
    
    if not image_paths:
        raise Exception("No AI images could be generated")
    
    # Create video clips from generated images
    per_image_duration = total_dur / len(image_paths)
    image_clips = []
    
    for image_path in image_paths:
        try:
            # Create image clip with proper duration and sizing
            img_clip = (ImageClip(image_path)
                       .with_duration(per_image_duration)
                       .resized((WIDTH, HEIGHT)))
            image_clips.append(img_clip)
        except Exception as e:
            print(f"‚ö†Ô∏è Error processing image {image_path}: {e}")
            continue
    
    if not image_clips:
        raise Exception("No valid image clips could be created")
    
    # Concatenate image clips
    video = concatenate_videoclips(image_clips).with_duration(total_dur)
    
    # Generate captions
    captions, caption_files = generate_caption_clips(moment['script'], idx, total_dur)
    
    # Compose final video with captions and audio
    final = CompositeVideoClip([video, *captions]).with_audio(audio).with_duration(total_dur)
    
    # Export final video
    outfile = os.path.join(outdir, f"ai_keymoment_{idx}.mp4")
    final.write_videofile(outfile, fps=24, codec="libx264", audio_codec="aac")
    
    # Cleanup temporary files
    audio.close()
    if os.path.exists(audio_file):
        os.remove(audio_file)
    
    for fname in caption_files:
        if os.path.exists(fname):
            os.remove(fname)
    
    for image_path in image_paths:
        if os.path.exists(image_path):
            os.remove(image_path)
    
    return outfile
